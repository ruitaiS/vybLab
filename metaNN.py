import numpy as np
from data import Data
from NN import NeuralNet

#Helper function for generateChild
#converts (integer) label into one-hot format
def oneHot(label, no_categories):
    res = np.full(no_categories,0.01)
    res[int(label)] = 0.99
    return res


class MetaNet:

    #Implemented in Sean's Code
    '''
    def train(self, input_vector, target_vector):
    def trainSubNet(self, input_vector, target_vector):
    def run(self, input_vector):
    def equals(self, NN):
    '''

    def __init__(self, number_of_subnet_labels=10):
        self.sub_net = NeuralNet(no_of_in_nodes = 28*28, 
                        no_of_out_nodes = number_of_subnet_labels, 
                        no_of_hidden_nodes = 60,
                        learning_rate = 0.1)
        self.super_net = NeuralNet(no_of_in_nodes = number_of_subnet_labels, 
                        no_of_out_nodes = 2, 
                        no_of_hidden_nodes = 15,
                        learning_rate = 0.1)
        
        #Alternate network with x labels
        #End up generating an NN with (# of subnet labels + x) labels

        #self.data_points = np.array([]) #TODO: Used by clustering algorithms
        #self.subnet_confusion_matrix = np.zeros((2, 2)) #[Predicted, Actuial]

    '''
    #Train the sub networks. data is a list of ((image, is_char), lab) lab is an int
    #The subnetworks predict, and detect when we have something new to add to the clustering algorithm.
    #DO NOT USE THIS UNLESS YOU SPECIFICALLY NEED TO, you can just use train and run below. 
    def train_sub_networks(self, data):
        print("Trainig sub-networks.")
        for d in data: 
            ((img, is_char), lab) = d
            if is_char: 
                t = self.sub_net.run(img)
                s = self.super_net.predict(t.flatten(), [0.0, 1.0])
                #Update the confusion matrix. 
                if np.argmax(s) == 1: 
                    self.subnet_confusion_matrix[1, 1] += 1
                else: 
                    self.subnet_confusion_matrix[0, 1] += 1
            else: 
                t = self.sub_net.predict(img, to_one_hot(lab))
                s = self.super_net.predict(t.flatten(), [1.0, 0.0])
                #Update the confusion matrix. 
                if np.argmax(s) == 1: 
                    self.subnet_confusion_matrix[1, 0] += 1
                else: 
                    self.subnet_confusion_matrix[0, 0] += 1
        l = len(data)
        self.subnet_confusion_matrix = np.array([x/l for x in self.subnet_confusion_matrix.reshape(4)]).reshape((2,2))
        print("Done training, Confusion Matrix:")
        print(self.subnet_confusion_matrix)
    '''

    #Train the model with the bit of input data. 
    #Returns prediction for (img_label, meta_label) as tuple, before training. 
    def train(self, img, img_label, meta_label):  #meta: 0 if seen before, 1 otherwise.
        result = self.sub_net.run(img).flatten()
        meta_result = self.super_net.run(result)

        #Train Sub and Meta Networks
        self.sub_net.train(img, oneHot(img_label, self.sub_net.no_of_out_nodes))
        self.super_net.train(result, oneHot(meta_label, self.super_net.no_of_out_nodes))

        #Return prediction result tuple
        if np.argmax(meta_result) == 1: #We have seen it before, return the result of sub network. 
            return (np.argmax(result), 1)
        else:                           #we have not seen it before go to alternate calssification method
            #TODO: Implement label generated by clustering algorithm
            #For now just return predicted img_label
            return (np.argmax(result), 0)

    def run(self, img): #meta: 0 if seen before, 1 otherwise.
        result = self.sub_net.run(img).flatten()
        meta_result = self.super_net.run(result)
        if np.argmax(meta_result) == 1: #We have seen it before, return the result of sub network. 
            return np.argmax(result)
        else:                           #we have not seen it before go to alternate calssification method
            #TODO: return result from clustering algorithm instead.
            return np.argmax(result)    
    
    def setSubNet(self, subNet):
        self.subNet = subNet    

    def generateChild(self, training_set, training_label):
        child = NeuralNet(no_of_in_nodes = 28*28,
            #Output vector size is equal to vector size of current network
            #As we create new categories each "generation" of network will have more outnodes
            no_of_out_nodes = len(self.run(training_set[0])), 
            no_of_hidden_nodes = 100,
            learning_rate = 0.1)

        wrong = 0
        total = 0
        for i in range(0, len(training_set)):
            #Child sees the training image, but the parent network decides what the label should be
            #child network never actually sees the 'real' label (and neither does the parent)
            label = np.argmax(self.run(training_set[i]))
            child.train(training_set[i], oneHot(label, 10))

            #Store how much the parents gets wrong
            if (label != training_label[i]):
                wrong += 1
            total += 1

        print("Percentage Mislabelled: " + str(wrong/total))
        return child






    #------------------------------------------------------------------------------------------------------------------
    # Meta needs an associated subnet
    # 
    # 
    #------------------------------------------------------------------------------------------------------------------
    #Basically same kinda stuff as was in v1.py in the old version

    #subnet, metanet, alternet

    #takes subnet and alternet as initialization parameters?

    #init with default learning rate? and then have functions that can manually set the learning rates of the networks

    #run & test as endpoints for Sean
        #May need some adjusting of the data for this one, since meta has slightly different label format